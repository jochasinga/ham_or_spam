{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ham_or_spam    \n",
    "\n",
    "Julia example of Naive Bayes spam mail classification.   \n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "Albeit being arguably the simplest algorithm in machine learning, [Bayes Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) is very powerful and practical in applications such as spam mail classification, recommendation system, and real-time prediction.\n",
    "\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) · P(A)}{P(B)}$$\n",
    "\n",
    "\n",
    "In the equation, $P$ stands for probability. $P(A)$ reads \"the probability of Event A occurring\" while $P(A|B)$ reads \"the probability of Event A occurring *provided* Event B happened.\"  \n",
    "\n",
    "Here is a practical Bayes Theorem application to solve any parent's problem:\n",
    "\n",
    "> What is the chance that my kid will contract sickness if another kid she plays with has a sniffle?\n",
    "\n",
    "Let `P(Sick)` stands for how often kids of the same age as that kid get sick in that given month, and `P(Sniffle)` for how often they have sniffles.\n",
    "\n",
    "**Example**: 20% of kids age 3-5 in California Bay Area are sick and contagious during any given month of November (`P(Sick) = 0.2`), but even more kids with sniffles (30%) (`P(Sniffle) = 0.3`). It's been known that 80% of all sick kids have sniffles (`P(Sniff|Sick) = 0.8`).\n",
    "\n",
    "```\n",
    "P(Sick|Sniff) = (P(Sniff|Sick) * P(Sick)) / P(Sniff)\n",
    "              = 0.8 * 0.2 / 0.3\n",
    "              = 0.16 / 0.3\n",
    "              = 0.53333...\n",
    "```\n",
    "\n",
    "Provided the kid has a sniffle, There is a **53%** chance that she will be sick.\n",
    "\n",
    "So the formula kind of tells us “forwards” when we know “backwards” (or vice versa).\n",
    "\n",
    "## Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes Classifier is basically a running application of Bayes Theorem.\n",
    "It calculates the probability of every input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/pieohpah/Code/julia/ham_spam/Project.toml\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activate current env\n",
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using DataStructures\n",
    "using Formatting\n",
    "\n",
    "most_common(c::Accumulator) = most_common(c, length(c))\n",
    "most_common(c::Accumulator, k) = sort(collect(c), by=kv->kv[2], rev=true)[1:k]\n",
    "\n",
    "function isalpha(str)\n",
    "    re = r\"^[+-]?([0-9]+([.][0-9]*)?|[.][0-9]+)$\"\n",
    "    !occursin(re, str)\n",
    "end\n",
    "\n",
    "\"Make a bag of words from email text.\"\n",
    "function make_dictionary(root_dir)\n",
    "    all_words = []\n",
    "    emails = [joinpath(root_dir, f) for f in readdir(root_dir)]\n",
    "    for (i, mail) in enumerate(emails)\n",
    "        open(mail) do m\n",
    "            for line in readlines(m)\n",
    "                words = split(line)\n",
    "                append!(all_words, words)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    bag = counter(all_words)\n",
    "    list_to_remove = [k for k in keys(bag)]\n",
    "\n",
    "    for item in list_to_remove\n",
    "        # remove if numerical\n",
    "        if !isalpha(item)\n",
    "            reset!(bag, item)\n",
    "            # pop!(bag, item)\n",
    "        elseif length(item) == 1\n",
    "            reset!(bag, item)\n",
    "            # pop!(bag, item)\n",
    "        end\n",
    "    end\n",
    "    # Consider only most 3000 common words\n",
    "    most_common(bag, 3000)\n",
    "end\n",
    "\n",
    "dict = make_dictionary(\"machine-learning-101/chapter1/train-mails\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Playing with count\n",
    "words = [\"foo\", \"fum\", \"fast\", \"foo\", \"fum\"]\n",
    "for word in words\n",
    "    c = count(x->x==word, words)\n",
    "    println(c)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function A(mail_dir)\n",
    "    files = [joinpath(mail_dir, f) for f in readdir(mail_dir)]\n",
    "    features_matrix = zeros(length(files), 3000)\n",
    "    train_labels = zeros(length(files))\n",
    "    files\n",
    "end\n",
    "\n",
    "\n",
    "function B()\n",
    "    files = A(\"machine-learning-101/chapter1/train-mails/\")\n",
    "    features_matrix = zeros(length(files), 3000)\n",
    "    train_labels = zeros(length(files))\n",
    "    count = 1\n",
    "    doc_id = 1\n",
    "    length(dict)\n",
    "    for file in files\n",
    "        open(file) do f\n",
    "            for (i, line) in enumerate(readlines(f))\n",
    "                if i == 3\n",
    "                    words = split(line)\n",
    "                    for word in words\n",
    "                        word_id = 1\n",
    "\n",
    "                        # Go through the bag of words\n",
    "                        for (i, d) in enumerate(dict)\n",
    "                            printfmt(\"d: {}\", d[1])\n",
    "                            if String(d[1]) == word\n",
    "                                word_id = i\n",
    "                                c = count(x -> x == word, words)\n",
    "                                println(c)\n",
    "                                features_matrix[doc_id, word_id] = c\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    features_matrix\n",
    "end\n",
    "\n",
    "fm = B()\n",
    "println(fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: objects of type Int64 are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Int64 are not callable",
      "",
      "Stacktrace:",
      " [1] (::getfield(Main, Symbol(\"##514#517\")){Array{Float64,2},Array{Float64,1},String})(::IOStream) at ./In[119]:19",
      " [2] #open#310(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::getfield(Main, Symbol(\"##514#517\")){Array{Float64,2},Array{Float64,1},String}, ::String) at ./iostream.jl:375",
      " [3] open at ./iostream.jl:373 [inlined]",
      " [4] extract_features(::String) at ./In[119]:8",
      " [5] top-level scope at In[119]:37"
     ]
    }
   ],
   "source": [
    "\"Make features matrix and label vector\"\n",
    "function extract_features(mail_dir, dict)\n",
    "    files = [joinpath(mail_dir, f) for f in readdir(mail_dir)]\n",
    "    features_matrix = zeros(length(files), 3000)\n",
    "    train_labels = zeros(length(files))\n",
    "    # cnt = 1\n",
    "    doc_id = 1\n",
    "    for (n, file) in enumerate(files)\n",
    "        open(file) do f\n",
    "            for (i, line) in enumerate(readlines(f))\n",
    "                # Skip the first subject line and second empty line\n",
    "                if i == 3\n",
    "                    words = split(line)\n",
    "                    for word in words\n",
    "                        word_id = 1\n",
    "                        # Go through the bag of words\n",
    "                        for (i, d) in enumerate(dict)\n",
    "                            if d[1] == word\n",
    "                                printfmt(\"Found {} in the bag\\n\", word)\n",
    "                                word_id = i\n",
    "                                c = count(x -> x == word, words)\n",
    "                                features_matrix[doc_id, word_id] = c\n",
    "                                printfmt(\"F[{}, {}] = {}\\n\", doc_id, word_id, c)\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "\n",
    "            train_labels[doc_id] = 0\n",
    "            filepath_tokens = split(file, \"/\")\n",
    "            last_token = filepath_tokens[length(filepath_tokens)]\n",
    "            if startswith(last_token, \"spmsg\")\n",
    "                train_labels[doc_id] = 1\n",
    "                # TODO: ?\n",
    "                # cnt += 1\n",
    "            end\n",
    "            doc_id += 1\n",
    "        end\n",
    "    end\n",
    "    (features_matrix, train_labels)\n",
    "end\n",
    "\n",
    "extract_features(\"./machine-learning-101/chapter1/train-mails\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
